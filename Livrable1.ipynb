{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livrable 1 - classification d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des dépendances\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dataset\n",
    "dataset_path = \"./Dataset/Dataset1\" # Chemin vers le dataset à modifier\n",
    "\n",
    "# Vérification de l'existence du dossier\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Le dossier {dataset_path} n'existe pas.\")\n",
    "\n",
    "# Récupération des classes et du nombre d'images par classe\n",
    "classes = []\n",
    "image_counts = []\n",
    "\n",
    "# Parcours des fichiers dans le dataset\n",
    "for class_name in os.listdir(dataset_path):  # Parcours des fichiers dans le dataset\n",
    "    class_path = os.path.join(dataset_path, class_name)  # Chemin vers le fichier\n",
    "    classes.append(class_name.replace('Dataset Livrable 1 - ',''))  # Ajout du nom de la classe sans l'extension\n",
    "    image_counts.append(len(os.listdir(class_path)))  # Comptage des fichiers dans le dossier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des classes et du nombre d'images par classe\n",
    "print(\"Classes : \", classes)\n",
    "print(\"Nombre d'images par classe : \", image_counts)\n",
    "\n",
    "# Affichage de l'histogramme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(classes, image_counts, color='skyblue')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Nombre d\\'images')\n",
    "plt.title('Répartition du nombre de données (images) par classe')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import imghdr\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Dictionnaire pour stocker le nombre d'images corrompues par classe\n",
    "corrupted_count_by_class = defaultdict(int)\n",
    "\n",
    "print(\"Début de la vérification des images ...\")\n",
    "\n",
    "# Parcours des fichiers ZIP\n",
    "for dir_name in os.listdir(dataset_path):\n",
    "    dir_path = os.path.join(dataset_path, dir_name)\n",
    "    for file_name in os.listdir(dir_path):\n",
    "                # Vérification si le fichier est bien une image\n",
    "                if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    try:\n",
    "                        # Ouverture de l'image pour vérifier si elle est corrompue\n",
    "                        with open(os.path.join(dir_path, file_name), 'rb') as file:\n",
    "                            img_bytes = file.read()  # Lire les bytes de l'image\n",
    "                            img = tf.image.decode_image(img_bytes)  # Essayer de décoder l'image\n",
    "                    except Exception as e:\n",
    "                        print(f\"Image {file_name} dans {dir_name} est corrompue. Exception: {e}\")\n",
    "                        corrupted_count_by_class[dir_name] += 1\n",
    "                else:\n",
    "                    print(f\"Le fichier {file_name} dans {dir_name} n'est pas une image.\")\n",
    "                    corrupted_count_by_class[dir_name] += 1\n",
    "\n",
    "print(\"Vérification des images dans les fichiers zip terminée.\")\n",
    "\n",
    "# Affichage du nombre d'images corrompues par fichier ZIP\n",
    "for dir_name, count in corrupted_count_by_class.items():\n",
    "    print(f\"Dossier {dir_name} : {count} images corrompues\")\n",
    "\n",
    "# Nombre total d'images corrompues\n",
    "total_corrupted = sum(corrupted_count_by_class.values())\n",
    "print(f\"Nombre total d'images corrompues : {total_corrupted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Afficher les n premières images de x\n",
    "def display_image(X, n):\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
    "        #plt.axis('off')\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout de donnée avec GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des dimensions de l'image et du bruit\n",
    "img_height, img_width = 64, 64\n",
    "channels = 1  # Pour des images en niveaux de gris (sketch)\n",
    "noise_dim = 100  # Dimension du vecteur de bruit\n",
    "\n",
    "# Générateur\n",
    "def build_generator():\n",
    "    model = Sequential([\n",
    "        layers.Dense(8 * 8 * 256, use_bias=False, input_shape=(noise_dim,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Reshape((8, 8, 256)),\n",
    "        layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(channels, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Discriminateur\n",
    "def build_discriminator():\n",
    "    model = Sequential([\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(img_height, img_width, channels)),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compilation des modèles\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Entraînement du GAN\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# Boucle d'entraînement\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # Génération d'images après chaque epoch\n",
    "        noise = tf.random.normal([16, noise_dim])\n",
    "        generated_images = generator(noise, training=False)\n",
    "\n",
    "        # Affichage des images générées\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Préparation des données pour la classe \"sketch\"\n",
    "sketch_path = os.path.join(dataset_path, \"sketch\")\n",
    "sketch_images = []\n",
    "for file_name in os.listdir(sketch_path):\n",
    "    img = Image.open(os.path.join(sketch_path, file_name)).convert('L').resize((img_height, img_width))\n",
    "    sketch_images.append(np.array(img) / 127.5 - 1)  # Normalisation entre -1 et 1\n",
    "sketch_images = np.expand_dims(sketch_images, axis=-1)\n",
    "sketch_dataset = tf.data.Dataset.from_tensor_slices(sketch_images).shuffle(1000).batch(32)\n",
    "\n",
    "# Entraînement du GAN\n",
    "train(sketch_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage d'échantillon de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
