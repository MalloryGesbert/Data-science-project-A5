{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2uHKuHEw8qt"
      },
      "source": [
        "# **PROJET LEYENDA - LIVRABLE 2 : TRAITEMENT D'IMAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XvA17VlzKv_"
      },
      "source": [
        "   ## **INTRODUCTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDUXASg40RG1"
      },
      "source": [
        "Dans le cadre du projet TouNum, l'objectif est de créer une solution entièrement automatisée pour analyser et générer des légendes d'images (captioning).\n",
        "Une étape essentielle pour atteindre cet objectif est d'améliorer la qualité des images afin de les rendre plus adaptées aux tâches ultérieures.\n",
        "\n",
        "La qualité des images peut avoir un impact significatif sur la précision des modèles de classification et de génération de légendes, en particulier lorsqu'on travaille avec des données bruitées ou de faible qualité.\n",
        "Par conséquent, une phase de prétraitement efficace des images est indispensable.\n",
        "\n",
        "Dans ce livrable, le but est de traiter un ensemble d'images bruitées et d'améliorer leur qualité grâce à une technique de débruitage.\n",
        "La méthode choisie repose sur l'utilisation d'autoencodeurs convolutionnels, un type d'architecture de réseau de neurones spécialement conçue pour le débruitage d'images.\n",
        "Les autoencodeurs convolutionnels combinent des couches de convolution, qui sont efficaces pour préserver les relations spatiales dans les images, avec la capacité de l'autoencodeur à apprendre des représentations efficaces des données d'entrée.\n",
        "Cette approche vise à supprimer le bruit tout en conservant les détails importants, ce qui donne des images de meilleure qualité pouvant améliorer la performance des algorithmes en aval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjK1DfV04t9b"
      },
      "source": [
        "## **Théorie : les DAE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJACOvla5BVa"
      },
      "source": [
        "Le Denoising Autoencoder est une extension des autoencodeurs classiques, spécifiquement conçue pour améliorer la qualité des données en éliminant le bruit. Contrairement à un autoencodeur traditionnel qui apprend à reproduire ses entrées, le DAE est entraîné avec des images volontairement dégradées, sur lesquelles du bruit est ajouté. L'objectif est que le modèle apprenne à reconstruire l'image d'origine à partir de cette version altérée.\n",
        "\n",
        "Cette approche présente plusieurs avantages majeurs. En premier lieu, elle empêche le réseau de se contenter de copier mécaniquement l'entrée, ce qui pourrait arriver avec un autoencodeur classique trop complexe. Ensuite, elle permet au modèle de se concentrer sur les caractéristiques importantes de l'image, en apprenant à distinguer les détails pertinents du bruit parasite. Enfin, cette stratégie renforce la robustesse du système face à des données de mauvaise qualité, ce qui est crucial dans le cadre du projet où les images brutes sont souvent bruitées ou de faible résolution.\n",
        "\n",
        "Grâce au Denoising Autoencoder, les images sont nettoyées avant d'être utilisées par les étapes suivantes du pipeline, comme la classification ou la génération de légendes. Cela contribue à améliorer la précision globale du système de traitement d'images automatique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loaMDruJ6MeW"
      },
      "source": [
        "![Architecture d'un DAE](DAE.jpeg)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TYTkFQZ5ryW"
      },
      "source": [
        "Pour entraîner efficacement le Denoising Autoencoder, il est essentiel d'évaluer la qualité de la reconstruction de l'image propre à partir de sa version bruitée. Cela se fait à l'aide d'une fonction de perte (loss function), qui mesure l'écart entre l'image originale et l'image reconstruite.\n",
        "\n",
        "Deux fonctions de perte sont couramment utilisées selon le format des données d'entrée :\n",
        "\n",
        "Mean Squared Error (MSE) : utilisée lorsque les pixels des images sont exprimés par des valeurs continues (par exemple entre 0 et 1 ou 0 à 255). Cette fonction calcule la moyenne des carrés des écarts entre les pixels de l'image originale et ceux de l'image générée.\n",
        "\n",
        "Binary Cross-Entropy (BCE) : préférable lorsque les images sont binarisées, c'est-à-dire que les pixels prennent uniquement les valeurs 0 ou 1. Cette fonction mesure la différence entre les distributions de pixels de l'entrée et de la sortie.\n",
        "\n",
        "Le choix de la fonction de perte dépend donc du type de données utilisées, et joue un rôle crucial dans l'optimisation des performances du modèle de débruitage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMLrlfKp_9NY"
      },
      "source": [
        "## 1. Prétraitement et préparation de l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d6zCz_fU6a3k"
      },
      "outputs": [],
      "source": [
        "# Import des librairies\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import visualkeras\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "# Affiche les graphiques Matplotlib directement dans le notebook Jupyter.\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extraction du dataset\n",
        "def extract_dataset(zip_path, extract_to):\n",
        "    \"\"\"\n",
        "    Extrait un dataset principal et les sous-zips associés dans des dossiers dédiés.\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): Chemin vers le fichier zip principal.\n",
        "        extract_to (str): Dossier où extraire les fichiers.\n",
        "    \"\"\"\n",
        "    zip_path = os.path.abspath(zip_path)\n",
        "    extract_to = os.path.abspath(extract_to)\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        raise FileNotFoundError(f\"Le fichier {zip_path} n'existe pas.\")\n",
        "    \n",
        "    if os.path.exists(extract_to):\n",
        "        shutil.rmtree(extract_to)\n",
        "        print(f\"Le dossier existant {extract_to} a été supprimé.\")\n",
        "\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "    # Étape 1 : extraire les sous-zips dans extract_to\n",
        "    with ZipFile(zip_path, 'r') as zip_ref:\n",
        "        for member in zip_ref.namelist():\n",
        "            filename = os.path.basename(member)\n",
        "            if filename and filename.endswith('.zip') and any(k in filename for k in ['Livrable 1 - Photo', 'Livrable 2']):\n",
        "                source = zip_ref.open(member)\n",
        "                target_path = os.path.join(extract_to, filename)\n",
        "                with open(target_path, \"wb\") as f:\n",
        "                    f.write(source.read())\n",
        "\n",
        "    # Étape 2 : Extrait tout les sous zip du dossier extrait\n",
        "    for root, dirs, files in os.walk(extract_to):\n",
        "        for file in files:\n",
        "            if file.endswith('.zip'):\n",
        "                sub_zip_path = os.path.join(root, file)\n",
        "                with ZipFile(sub_zip_path, 'r') as sub_zip_ref:\n",
        "                    sub_zip_ref.extractall(root)\n",
        "                os.remove(sub_zip_path)  # Supprime le zip après extraction\n",
        "\n",
        "    print(f\"Dataset extrait dans le dossier : {extract_to}\")\n",
        "\n",
        "\n",
        "def load_images(folder_path):\n",
        "    \"\"\"\n",
        "    Charge toutes les images en mémoire et assure la cohérence des canaux.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Chemin vers le dataset.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    valid_ext = ('.png', '.jpg', '.jpeg')\n",
        "\n",
        "    # Convertir le chemin en chemins absolus pour éviter les erreurs\n",
        "    folder_path = os.path.abspath(folder_path)\n",
        "\n",
        "    # 1. Chargement et vérification des images\n",
        "    if not os.path.exists(folder_path):\n",
        "        raise FileNotFoundError(f\"Dossier introuvable : {folder_path}\")\n",
        "\n",
        "    for f in os.listdir(folder_path):\n",
        "        if f.lower().endswith(valid_ext):\n",
        "            img = Image.open(os.path.join(folder_path, f))\n",
        "            # Converti en RGB si necessaire pour assurer la coherence\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "            images.append(np.array(img))\n",
        "\n",
        "    if not images:\n",
        "        raise ValueError(\"Aucune image valide trouvée\")\n",
        "\n",
        "    return images\n",
        " \n",
        "def check_image_resolutions(folder):\n",
        "    \"\"\"\n",
        "    Fonction pour obtenir les résolutions des images d'origine.\n",
        "\n",
        "    Args:\n",
        "        folder (str): Chemin vers le dataset.\n",
        "    \"\"\"\n",
        "    # Convertir le chemin en chemin absolu pour éviter les erreurs\n",
        "    folder = os.path.abspath(folder)\n",
        "\n",
        "    resolutions = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            resolutions.append(img.shape[:2])  # (hauteur, largeur)\n",
        "    return resolutions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le dossier existant c:\\Users\\mallo\\OneDrive\\Bureau\\CESI 2022 - 2025\\Annee 5\\Semestre 10\\Option data science\\Project\\Data-science-project-A5\\Dataset\\Dataset2 a été supprimé.\n",
            "Dataset extrait dans le dossier : c:\\Users\\mallo\\OneDrive\\Bureau\\CESI 2022 - 2025\\Annee 5\\Semestre 10\\Option data science\\Project\\Data-science-project-A5\\Dataset\\Dataset2\n"
          ]
        }
      ],
      "source": [
        "# Appel de la fonction pour extraire le dataset\n",
        "dataset_zip_path = './Dataset/Datasets.zip'\n",
        "extract_dataset(dataset_zip_path, './Dataset/Dataset2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurations principales de nos modèles\n",
        "dataset_path = './Dataset/Dataset2/'\n",
        "dataset_train_path = './Dataset/Dataset2/photo/'\n",
        "dataset_test_path = './Dataset/Dataset2/Dataset/'\n",
        "\n",
        "img_size = (256, 256)  # Taille de l'image\n",
        "num_samples = 6 # Nombre d'échantillons à afficher\n",
        "learning_rate = 0.01  # Taux d'apprentissage\n",
        "epochs = 25 # nombre epoch alogithme debruiter\n",
        "batch_size = 32 # taille batch de traitement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger les images du dataset 1\n",
        "images = load_images(dataset_train_path)\n",
        "images_noisy = load_images(dataset_test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charge les résolutions des images\n",
        "resolutions = check_image_resolutions(dataset_train_path)\n",
        "heights = [res[0] for res in resolutions]\n",
        "widths = [res[1] for res in resolutions]\n",
        "\n",
        "resolutions_test = check_image_resolutions(dataset_test_path)\n",
        "heights_test = [res[0] for res in resolutions_test]\n",
        "widths_test = [res[1] for res in resolutions_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "wIuoj-gbKu-r",
        "outputId": "a67a8ccc-7ab5-403b-8f9e-42a7917b4c99"
      },
      "outputs": [],
      "source": [
        "# 3. Affichage de quelques images avec leurs résolutions d'origine\n",
        "fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
        "for i in range(min(num_samples, len(images))):  # Sélectionner quelques images au hasard pour les afficher\n",
        "    axes[i].imshow(images[i])\n",
        "    axes[i].set_title(f\" {heights[i]}x{widths[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovA0wSd3yvMb"
      },
      "source": [
        "## Redimensionnement du Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBcB42vcy6Nu"
      },
      "source": [
        "Le fait que nos images aient différentes résolutions crée des défis pour l'entraînement d'un modèle de machine learning, notamment pour les réseaux de neurones convolutionnels (CNN), qui nécessitent des images uniformes. Voici pourquoi le redimensionnement est important :\n",
        "\n",
        "1. **Uniformisation des données** : En redimensionnant toutes les images à une taille commune (par exemple, 128x128 ou 256x256), nous assurons que chaque image a le même nombre de pixels, facilitant ainsi l'apprentissage.\n",
        "\n",
        "2. **Optimisation des performances** : Les résolutions élevées demandent plus de mémoire et ralentissent l'entraînement. Le redimensionnement permet de réduire la complexité tout en gardant l'essentiel des informations visuelles.\n",
        "\n",
        "3. **Réduction des biais** : Des images de tailles différentes peuvent introduire un biais, où les plus grandes images sont privilégiées. Le redimensionnement garantit un traitement équitable de toutes les images.\n",
        "\n",
        "4. **Simplification du prétraitement** : Le redimensionnement facilite également les étapes de prétraitement (comme l'ajout ou le débruitage) en garantissant des tailles uniformes.\n",
        "\n",
        "Le choix de la taille de redimensionnement dépend du compromis entre la conservation des détails visuels et les exigences en ressources. Par exemple, 128x128 est adapté pour des projets légers, tandis que 256x256 conserve plus de détails mais consomme plus de mémoire et de calcul."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxi64bHQLCYx"
      },
      "outputs": [],
      "source": [
        "# 4. Fonction pour Redimensionner les images\n",
        "def resize_images(images, target_size=img_size):\n",
        "    \"\"\"Redimensionne toutes les images et les convertit en RGB\"\"\"\n",
        "    resized_images = []\n",
        "    for img in images:\n",
        "        img_pil = Image.fromarray(img).convert('RGB')  # Forcer en RGB\n",
        "        img_resized = img_pil.resize(target_size)\n",
        "        resized_images.append(np.array(img_resized))\n",
        "    return np.array(resized_images)\n",
        "\n",
        "resized_images = resize_images(images, target_size=img_size)\n",
        "resized_images_noisy = resize_images(images_noisy, target_size=img_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbVDo-VoPqfV"
      },
      "source": [
        "## Affichage d'échantillon de data correcte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "iLYn-j1qLFVi",
        "outputId": "7e6c7b78-81b1-4b93-a1e4-2176af08b516"
      },
      "outputs": [],
      "source": [
        "# 5. Affichage des images redimensionnées\n",
        "all_images = np.concatenate([resized_images,resized_images_noisy], axis=0)\n",
        "all_images = np.array(all_images)\n",
        "images_train =np.array(resized_images)\n",
        "images_validation =np.array(resized_images_noisy)\n",
        "print(f\"Nombre d'images dans notre dataset : {len(all_images)}\")\n",
        "\n",
        "\n",
        "def display_images(images, num_samples=5):\n",
        "    \"\"\"Affiche un échantillon d'images\"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(min(num_samples, len(all_images))):\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()  # Ajout pour éviter le chevauchement\n",
        "    plt.show()\n",
        "\n",
        "# Appel de la fonction\n",
        "display_images(all_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un_FzaptQl8W"
      },
      "source": [
        "Dans cette partie, nous chargeons les images du dataset, vérifions leurs résolutions et les redimensionnons à une taille uniforme (256x256 pixels). Cela garantit que toutes les images ont les mêmes dimensions, ce qui est essentiel pour l’entraînement du modèle d'autoencodeur.\n",
        "\n",
        "Nous pouvons également constaté que nous n'avons que 148 images dans notre Dataset ce qui est très peu pour notre modèle. C'est un risque de surapprentissage (overfitting). Avec un petit dataset, il est facile pour un modèle de surapprendre les données, c'est-à-dire de mémoriser les images spécifiques au lieu d'apprendre des motifs généraux.\n",
        "\n",
        "Un petit dataset limite la quantité d'informations que le modèle peut exploiter, ce qui pourrait limiter ses performances finales, surtout sur des architectures complexes comme les autoencodeurs convolutionnels, qui ont beaucoup de paramètres à entraîner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cjViwXSb1DY"
      },
      "source": [
        "## Analyse des pixels et des couleurs des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JcmDQ8GY07r",
        "outputId": "609c7fc6-fce1-4af5-b00d-df44393e11e6"
      },
      "outputs": [],
      "source": [
        "#Analyse des pixels : calcul des statistiques\n",
        "\n",
        "def calculate_image_statistics(all_images):\n",
        "    \"\"\"Calcule des statistiques sur les images\"\"\"\n",
        "    pixel_values  = np.concatenate([img.ravel() for img in images]) #Rassemble tous les pixels de toutes les images en un seul tableau unidimensionnel\n",
        "    mean = np.mean(pixel_values)\n",
        "    std = np.std(pixel_values)\n",
        "    median = np.median(pixel_values)\n",
        "\n",
        "    return mean, std, median, pixel_values\n",
        "\n",
        "# mean, std, median, pixel_values = calculate_image_statistics(all_images)\n",
        "\n",
        "#Affichage des statistiques\n",
        "# print(f\"Moyenne : {mean}\")\n",
        "# print(f\"Écart type : {std}\")\n",
        "# print(f\"Médiane : {median}\")\n",
        "\n",
        "#Fonction pour visualiser la distribution des couleurs\n",
        "def plot_color_distribution(all_images):\n",
        "    \"\"\"Affiche la distribution des couleurs des images\"\"\"\n",
        "    reds = np.concatenate([img[:, :, 2].ravel() for img in images])\n",
        "    greens = np.concatenate([img[:, :, 1].ravel() for img in images])\n",
        "    blues = np.concatenate([img[:, :, 0].ravel() for img in images])\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(reds, bins=50, color='red', alpha=0.5, label='Rouge') #extrait la composante rouge de chaque image, aplatit ces valeurs en un vecteur puis concatène tous ces vecteurs en un seul grand vecteur reds\n",
        "    plt.hist(greens, bins=50, color='green', alpha=0.5, label='Vert')\n",
        "    plt.hist(blues, bins=50, color='blue', alpha=0.5, label='Bleu')\n",
        "    plt.title(\"Distribution des couleurs des images\")\n",
        "    plt.xlabel(\"Valeur des pixel (0-255)\")\n",
        "    plt.ylabel(\"Nombre de pixels\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkRyVXG3kOGF"
      },
      "source": [
        "Dans notre jeu d'images, après avoir analysé les valeurs des pixels, voici les résultats obtenus :\n",
        "\n",
        "Moyenne des pixels : 117.68\n",
        "\n",
        "Écart-type des pixels : 71.70\n",
        "\n",
        "Médiane des pixels : 115.00\n",
        "\n",
        "\n",
        "Interprétation des résultats :\n",
        "Moyenne des pixels : La moyenne est proche du centre de la plage [0, 255], indiquant que nos images ont une luminosité moyenne légèrement plus sombre que le milieu de l'échelle. Elles contiennent un bon équilibre entre zones sombres et claires, mais avec une légère prédominance de zones sombres.\n",
        "\n",
        "Médiane des pixels : La médiane est très proche de la moyenne, ce qui montre que la distribution des pixels est relativement symétrique, sans valeurs extrêmes.\n",
        "\n",
        "Écart-type : L'écart-type élevé (71.70) indique une grande variabilité des pixels, avec un bon contraste entre les zones très sombres et très claires, ce qui est utile pour les algorithmes de traitement d'image.\n",
        "\n",
        "\n",
        "Nos images ont une luminosité légèrement inférieure à la moyenne, une distribution symétrique des valeurs de pixels et un bon contraste. Cela est idéal pour les phases de traitement d'image, car cela permet au modèle de mieux détecter les détails et les transitions dans les images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "CcXUpHKyj6Wk",
        "outputId": "08423cdc-893e-4ba5-c8ec-cb6d276eb389"
      },
      "outputs": [],
      "source": [
        "# plot_color_distribution(all_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoAji-BLlBMR"
      },
      "source": [
        "Contraste dans les Images :\n",
        "Les pics aux extrêmes (0 et 1) dans la distribution des pixels indiquent un fort contraste dans les images, ce qui est important pour la netteté des bords et les zones de transition rapide. Lors du traitement, il est crucial de préserver ces zones pour ne pas altérer les détails fins et maintenir la clarté de l'image.\n",
        "\n",
        "Variabilité des Couleurs :\n",
        "Les différentes distributions entre les canaux (rouge, vert, bleu) montrent une bonne diversité des couleurs, bien que les teintes bleutées prédominent légèrement. Cela peut influencer la manière dont l'autoencodeur doit traiter chaque canal pour améliorer la qualité globale tout en respectant cette variation de couleurs.\n",
        "\n",
        "Ajout de Bruit et Dégradation :\n",
        "Lors de l'ajout de bruit, il est essentiel d'observer comment le bruit affecte les pics aux extrêmes et les zones intermédiaires. Lors du débruitage, l'autoencodeur doit être capable de reconstruire correctement ces zones de fort contraste et les couleurs dominantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "w0JJYdzN6a3p",
        "outputId": "e9867b7f-aead-4c0d-f52c-c3d31d8601ca"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(images):\n",
        "    \"\"\"Normalisation et redimensionnement\"\"\"\n",
        "    images = images.astype('float32') / 255.  # Normalisation\n",
        "    return images\n",
        "\n",
        "# Split train/test\n",
        "x_train, x_test = train_test_split(images_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Application du prétraitement\n",
        "x_train = preprocess_data(x_train)\n",
        "x_test = preprocess_data(x_test)\n",
        "x_validation = preprocess_data(images_validation)\n",
        "\n",
        "print(f\"\\nForme des données :\")\n",
        "print(f\"Train: {x_train.shape} (ex: {x_train[0].shape})\")\n",
        "print(f\"Nombre d'images d'entrainement : {len(x_train) }\")\n",
        "print(f\"Test: {x_test.shape} (ex: {x_test[0].shape})\")\n",
        "print(f\"Nombre d'images test : {len(x_test) }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FyJdTzP6a3p"
      },
      "outputs": [],
      "source": [
        "display_images(x_train, num_samples=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HvWpCfl6a3q"
      },
      "source": [
        "# Auto-encodeur de réduction de bruit (denoiser)\n",
        "## Ajout du bruit au images :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_noise_2(images, noise_type=\"gaussian\", noise_factor=0.2):\n",
        "    if noise_type == \"gaussian\":\n",
        "        noise = noise_factor * np.random.normal(0.0, 1.0, images.shape).astype(np.float32)\n",
        "        noisy_images = images + noise\n",
        "\n",
        "    elif noise_type == \"poisson\":\n",
        "        noisy_images = (1 - noise_factor) * images + noise_factor * (np.random.poisson(images * 255) / 255)\n",
        "\n",
        "    elif noise_type == \"speckle\":\n",
        "        noise = noise_factor * np.random.randn(*images.shape).astype(np.float32)\n",
        "        noisy_images = images + images * noise\n",
        "\n",
        "    elif noise_type == \"salt_pepper\":\n",
        "        rnd = np.random.rand(*images.shape)\n",
        "        noisy_images = np.where(rnd < noise_factor / 2, 0.,\n",
        "                        np.where(rnd > 1 - noise_factor / 2, 1., images))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unknown noise type\")\n",
        "\n",
        "    return np.clip(noisy_images, 0., 1.).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_noise_batch(x_data, noise_type):\n",
        "    return np.array([add_noise_2(img, noise_type) for img in x_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ercmZR086a3q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add_noise(images, noise_type=\"gaussian\", noise_factor=0.2):\n",
        "    noisy_images = images.copy()\n",
        "\n",
        "    if noise_type == \"gaussian\":\n",
        "        noise = noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
        "        noisy_images += noise\n",
        "\n",
        "    elif noise_type == \"poisson\":\n",
        "        noise = np.random.poisson(images * 255.0) / 255.0  # Convert to 0-1 range\n",
        "        noisy_images += (1-noise_factor) * images + noise_factor * noise\n",
        "\n",
        "    elif noise_type == \"speckle\":\n",
        "        noise = noise_factor * np.random.randn(*images.shape)\n",
        "        noisy_images += images * noise\n",
        "\n",
        "    elif noise_type == \"salt_pepper\":\n",
        "        prob = noise_factor / 2\n",
        "        rnd = np.random.rand(*images.shape)\n",
        "        noisy_images[rnd < prob] = 0  # Sel (noir)\n",
        "        noisy_images[rnd > (1 - prob)] = 1  # Poivre (blanc)\n",
        "\n",
        "    return np.clip(noisy_images, 0., 1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Appliquer plusieurs types de bruits\n",
        "x_train_noisy_gaussian = add_noise_batch(x_train, \"gaussian\")\n",
        "x_test_noisy_gaussian = add_noise_batch(x_test, \"gaussian\")\n",
        "\n",
        "x_train_noisy_poisson = add_noise_batch(x_train, \"poisson\")\n",
        "x_test_noisy_poisson = add_noise_batch(x_test, \"poisson\")\n",
        "\n",
        "x_train_noisy_speckle = add_noise_batch(x_train, \"speckle\")\n",
        "x_test_noisy_speckle = add_noise_batch(x_test, \"speckle\")\n",
        "\n",
        "x_train_noisy_sp = add_noise_batch(x_train, \"salt_pepper\")\n",
        "x_test_noisy_sp = add_noise_batch(x_test, \"salt_pepper\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSa1gFmx6a3q"
      },
      "outputs": [],
      "source": [
        "print(\"Images d'origine :\")\n",
        "display_images(x_train, num_samples=5)\n",
        "print(\"Images bruitées (gaussien) :\")\n",
        "display_images(x_train_noisy_gaussian, num_samples=5)\n",
        "print(\"Images bruitées (poisson) :\")\n",
        "display_images(x_train_noisy_poisson, num_samples=5)\n",
        "print(\"Images bruitées (speckle) :\")\n",
        "display_images(x_train_noisy_speckle, num_samples=5)\n",
        "print(\"Images bruitées (sel et poivre) :\")\n",
        "display_images(x_train_noisy_sp, num_samples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO-mAuN16a3q"
      },
      "outputs": [],
      "source": [
        "print(\"Dimensions des données :\")\n",
        "print(\"x_test shape:\", x_test.shape)          # Doit être (N, 256, 256, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dXGFhe06a3r"
      },
      "source": [
        "## Encodeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Input, Flatten, Dense, Reshape\n",
        "\n",
        "# Entrée de l'image\n",
        "input_img = Input(shape=(img_size[0], img_size[1], 3))  # à adapter selon ta taille d’image\n",
        "\n",
        "# Bloc 1\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Bloc 2\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrGIDQM56a3r"
      },
      "source": [
        "## Decodeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoW4O1BK6a3r"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import UpSampling2D, Dropout\n",
        "\n",
        "# Bloc 1\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "# Bloc 2\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "# Dernière couche (sortie)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RudsBP3I6a3s"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Création des modèles basqiques pour chaque bruit\n",
        "autoencoder_gaussian = Model(input_img, decoded)\n",
        "autoencoder_poisson = Model(input_img, decoded)\n",
        "autoencoder_speckle = Model(input_img, decoded)\n",
        "autoencoder_sp = Model(input_img, decoded)\n",
        "\n",
        "# Compilation des modèles basique pour chaque bruit\n",
        "autoencoder_gaussian.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse',  metrics=['accuracy'])  # MSE au lieu de binary_crossentropy pour les images continues\n",
        "autoencoder_poisson.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse',  metrics=['accuracy'])  # MSE au lieu de binary_crossentropy pour les images continues\n",
        "autoencoder_speckle.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse',  metrics=['accuracy'])  # MSE au lieu de binary_crossentropy pour les images continues\n",
        "autoencoder_sp.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse',  metrics=['accuracy'])  # MSE au lieu de binary_crossentropy pour les images continues\n",
        "\n",
        "# Compilation des modèles avec custom loss pour chaque bruit\n",
        "def custom_kl_loss(y_true, y_pred):\n",
        "    # Ajout d'un epsilon pour éviter les log(0)\n",
        "    epsilon = 1e-7\n",
        "    y_true = tf.clip_by_value(y_true, epsilon, 1.0)\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)\n",
        "\n",
        "    # KL divergence : KL(y_true || y_pred)\n",
        "    kl = y_true * tf.math.log(y_true / y_pred)\n",
        "    return tf.reduce_mean(tf.reduce_sum(kl, axis=[1, 2, 3]))  # Moyenne sur les batchs\n",
        "\n",
        "# # Création des modèles avec custom loss pour chaque bruit\n",
        "# autoencoder_gaussian_kl = Model(input_img, decoded)\n",
        "# autoencoder_poisson_kl = Model(input_img, decoded)\n",
        "# autoencoder_speckle_kl = Model(input_img, decoded)\n",
        "# autoencoder_sp_kl = Model(input_img, decoded)\n",
        "\n",
        "# # Compilation des modèles avec custom loss pour chaque bruit\n",
        "# autoencoder_gaussian_kl.compile(optimizer=Adam(learning_rate=learning_rate), loss=custom_kl_loss, metrics=['accuracy'])\n",
        "# autoencoder_poisson_kl.compile(optimizer=Adam(learning_rate=learning_rate), loss=custom_kl_loss, metrics=['accuracy'])\n",
        "# autoencoder_speckle_kl.compile(optimizer=Adam(learning_rate=learning_rate), loss=custom_kl_loss, metrics=['accuracy'])\n",
        "# autoencoder_sp_kl.compile(optimizer=Adam(learning_rate=learning_rate), loss=custom_kl_loss, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Affichage du résumé d'un des modèles\n",
        "autoencoder_gaussian.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Affichage de l'architecture d'un modèle classique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "# plot_model(autoencoder_gaussian, to_file='autoencoder_architecture.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "import visualkeras\n",
        "visualkeras.layered_view(autoencoder_gaussian, to_file='./autoencoder.png',\n",
        "    legend=True,                                 \n",
        "    scale_xy=1.5,               \n",
        "    scale_z=0.6,               \n",
        "    spacing=40,                \n",
        "    draw_volume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvDqjVfN6a3s"
      },
      "source": [
        "## Entrainement des modèles\n",
        "\n",
        "Cette partie comprant l'entrainement de modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "# Création d'une fonction pour générer les checkpoints\n",
        "def create_checkpoint_callback(name):\n",
        "    return ModelCheckpoint(\n",
        "        filepath=f'checkpoints/model{name}_epoch{{epoch:02d}}_valLoss{{val_loss:.4f}}.h5',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        mode='min',\n",
        "        verbose=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liste des modèles, des jeux de données, et des noms\n",
        "models_data = [\n",
        "    (\"Gaus\", autoencoder_gaussian, x_train_noisy_gaussian, x_test_noisy_gaussian),\n",
        "    # (\"Pois\", autoencoder_poisson, x_train_noisy_poisson, x_test_noisy_poisson),\n",
        "    # (\"Spec\", autoencoder_speckle, x_train_noisy_speckle, x_test_noisy_speckle),\n",
        "    (\"Salt\", autoencoder_sp, x_train_noisy_sp, x_test_noisy_sp)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionnaire pour stocker l'historique d'entraînement de chaque modèle\n",
        "histories = {}\n",
        "# histories = [\n",
        "#     (\"Gaussian Noise\", history_gaussian),\n",
        "#     (\"Poisson Noise\", history_poisson),\n",
        "#     (\"Speckle Noise\", history_speckle),\n",
        "#     (\"Salt & Pepper Noise\", history_sp),\n",
        "# ]\n",
        "\n",
        "\n",
        "# Entraînement en boucle\n",
        "for name, model, x_train_noisy, x_test_noisy in models_data:\n",
        "    print(f\"\\n--- Entraînement du modèle {name} ---\")\n",
        "    checkpoint = create_checkpoint_callback(name)\n",
        "\n",
        "    # Entraînement du modèle\n",
        "    history = model.fit(\n",
        "        x_train_noisy, x_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        validation_data=(x_test_noisy, x_test),\n",
        "        callbacks=[checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Sauvegarde de l'historique dans un dictionnaire\n",
        "    histories[name] = history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Checkpoint callback\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# checkpoint_callback_gaus = ModelCheckpoint(\n",
        "#     filepath='checkpoints/modelGaus_epoch{epoch:02d}_valLoss{val_loss:.4f}.h5',\n",
        "#     monitor='val_loss',              # Surveille la perte de validation\n",
        "#     save_best_only=True,             # Sauvegarde uniquement si la validation loss s'améliore\n",
        "#     save_weights_only=False,         # Sauvegarder tout le modèle (pas seulement les poids)\n",
        "#     mode='min',                      # Car on cherche à minimiser la validation loss\n",
        "#     verbose=1                        # Affiche un log à chaque sauvegarde\n",
        "# )\n",
        "# checkpoint_callback_pois = ModelCheckpoint(\n",
        "#     filepath='checkpoints/modelPois_epoch{epoch:02d}_valLoss{val_loss:.4f}.h5',\n",
        "#     monitor='val_loss',              # Surveille la perte de validation\n",
        "#     save_best_only=True,             # Sauvegarde uniquement si la validation loss s'améliore\n",
        "#     save_weights_only=False,         # Sauvegarder tout le modèle (pas seulement les poids)\n",
        "#     mode='min',                      # Car on cherche à minimiser la validation loss\n",
        "#     verbose=1                        # Affiche un log à chaque sauvegarde\n",
        "# )\n",
        "# checkpoint_callback_spec = ModelCheckpoint(\n",
        "#     filepath='checkpoints/modelSpec_epoch{epoch:02d}_valLoss{val_loss:.4f}.h5',\n",
        "#     monitor='val_loss',              # Surveille la perte de validation\n",
        "#     save_best_only=True,             # Sauvegarde uniquement si la validation loss s'améliore\n",
        "#     save_weights_only=False,         # Sauvegarder tout le modèle (pas seulement les poids)\n",
        "#     mode='min',                      # Car on cherche à minimiser la validation loss\n",
        "#     verbose=1                        # Affiche un log à chaque sauvegarde\n",
        "# )\n",
        "# checkpoint_callback_salt = ModelCheckpoint(\n",
        "#     filepath='checkpoints/modelSalt_epoch{epoch:02d}_valLoss{val_loss:.4f}.h5',\n",
        "#     monitor='val_loss',              # Surveille la perte de validation\n",
        "#     save_best_only=True,             # Sauvegarde uniquement si la validation loss s'améliore\n",
        "#     save_weights_only=False,         # Sauvegarder tout le modèle (pas seulement les poids)\n",
        "#     mode='min',                      # Car on cherche à minimiser la validation loss\n",
        "#     verbose=1                        # Affiche un log à chaque sauvegarde\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrâinement des modèles classiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILBRszLp6a3s"
      },
      "outputs": [],
      "source": [
        "# # Entraînement des modèles classiques\n",
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        "# # x_test_noisy_gaussian = x_test_noisy_gaussian.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# history_gaussian = autoencoder_gaussian.fit(\n",
        "#     x_train_noisy_gaussian, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_gaussian, x_test),\n",
        "#     callbacks=[checkpoint_callback_gaus]\n",
        "# )\n",
        "\n",
        "# # x_test_noisy_poisson = x_test_noisy_poisson.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# history_poisson = autoencoder_poisson.fit(\n",
        "#     x_train_noisy_poisson, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_poisson, x_test),\n",
        "#     callbacks=[checkpoint_callback_pois]\n",
        "# )\n",
        "\n",
        "# # x_test_noisy_speckle = x_test_noisy_speckle.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# history_speckle = autoencoder_speckle.fit(\n",
        "#     x_train_noisy_speckle, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_speckle, x_test),\n",
        "#     callbacks=[checkpoint_callback_spec]\n",
        "# )\n",
        "\n",
        "# # x_test_noisy_sp = x_test_noisy_sp.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# history_sp = autoencoder_sp.fit(\n",
        "#     x_train_noisy_sp, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_sp, x_test),\n",
        "#     callbacks=[checkpoint_callback_salt]\n",
        "# )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entraînement des modèles avec une custom loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Entraînement des modèles avec custom loss\n",
        "# history_gaussian_kl = autoencoder_gaussian_kl.fit(\n",
        "#     x_train_noisy_gaussian, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_gaussian, x_test)\n",
        "# )\n",
        "# history_poisson_kl = autoencoder_poisson_kl.fit(\n",
        "#     x_train_noisy_poisson, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_poisson, x_test)\n",
        "# )\n",
        "# history_speckle_kl = autoencoder_speckle_kl.fit(\n",
        "#     x_train_noisy_speckle, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_speckle, x_test)\n",
        "# )\n",
        "# history_sp_kl = autoencoder_sp_kl.fit(\n",
        "#     x_train_noisy_sp, x_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     validation_data=(x_test_noisy_sp, x_test)\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sauvegarde des modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarde des modèles classique\n",
        "# autoencoder_gaussian.save(\"autoencoder_gaussian2.h5\")\n",
        "# autoencoder_gaussian.save(\"autoencoder_gaussian2.keras\")\n",
        "\n",
        "# autoencoder_poisson.save(\"autoencoder_poisson2.h5\")\n",
        "# autoencoder_poisson.save(\"autoencoder_poisson2.keras\")\n",
        "\n",
        "# autoencoder_speckle.save(\"autoencoder_speckle2.h5\")\n",
        "# autoencoder_speckle.save(\"autoencoder_speckle2.keras\")\n",
        "\n",
        "# autoencoder_sp.save(\"autoencoder_sp2.h5\")\n",
        "# autoencoder_sp.save(\"autoencoder_sp2.keras\")\n",
        "\n",
        "# # Sauvegarde des modèles avec custom loss\n",
        "# autoencoder_gaussian_kl.save(\"autoencoder_gaussian2.h5\")\n",
        "# autoencoder_gaussian_kl.save(\"autoencoder_gaussian2.keras\")\n",
        "\n",
        "# autoencoder_poisson_kl.save(\"autoencoder_poisson2.h5\")\n",
        "# autoencoder_poisson_kl.save(\"autoencoder_poisson2.Keras\")\n",
        "\n",
        "# autoencoder_speckle_kl.save(\"autoencoder_speckle2.h5\")\n",
        "# autoencoder_speckle_kl.save(\"autoencoder_speckle2.keras\")\n",
        "\n",
        "# autoencoder_sp_kl.save(\"autoencoder_sp2.h5\")\n",
        "# autoencoder_sp_kl.save(\"autoencoder_sp2.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation des metrics des modèles\n",
        "### Metrics modèles classiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Visualisation des pertes d'apprentissage (Train) et de validation (Test)\n",
        "# fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "# fig.suptitle(\"Évolution de la perte (loss) par type de bruit\", fontsize=16)\n",
        "\n",
        "# for i, (title, history) in enumerate(histories):\n",
        "#     ax = axes[i]\n",
        "#     ax.plot(history.history['loss'], label='Train Loss')\n",
        "#     ax.plot(history.history['val_loss'], label='Validation Loss')\n",
        "#     ax.set_title(title, fontsize=12)\n",
        "#     ax.set_xlabel('Epochs')\n",
        "#     ax.set_ylabel('Loss')\n",
        "#     ax.grid(True, linestyle='--', alpha=0.5)\n",
        "#     ax.legend()\n",
        "\n",
        "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Création de deux sous-graphes : un pour la Loss, un pour l'Accuracy\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# --- PLOT LOSS ---\n",
        "for name, history in histories.items():\n",
        "    axes[0].plot(history.history['loss'], label=f'{name} - Train')\n",
        "    if 'val_loss' in history.history:\n",
        "        axes[0].plot(history.history['val_loss'], linestyle='--', label=f'{name} - Val')\n",
        "\n",
        "axes[0].set_title('Loss par modèle')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# --- PLOT ACCURACY ---\n",
        "for name, history in histories.items():\n",
        "    if 'accuracy' in history.history:\n",
        "        axes[1].plot(history.history['accuracy'], label=f'{name} - Train')\n",
        "    if 'val_accuracy' in history.history:\n",
        "        axes[1].plot(history.history['val_accuracy'], linestyle='--', label=f'{name} - Val')\n",
        "\n",
        "axes[1].set_title('Accuracy par modèle')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSFwRx2O6a3s"
      },
      "outputs": [],
      "source": [
        "# # Visualisation des pertes d'apprentissage (Train) et de validation (Test) des modèles classiques\n",
        "\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "# # Gaussian Noise\n",
        "# axes[0].plot(history_gaussian.history['loss'], label='Train')\n",
        "# axes[0].plot(history_gaussian.history['val_loss'], label='Test')\n",
        "# axes[0].set_title(\"Gaussian Noise\")\n",
        "# axes[0].set_xlabel('Epochs')\n",
        "# axes[0].set_ylabel('Loss')\n",
        "# axes[0].legend()\n",
        "\n",
        "# # Poisson Noise\n",
        "# axes[1].plot(history_poisson.history['loss'], label='Train')\n",
        "# axes[1].plot(history_poisson.history['val_loss'], label='Test')\n",
        "# axes[1].set_title(\"Poisson Noise\")\n",
        "# axes[1].set_xlabel('Epochs')\n",
        "# axes[1].set_ylabel('Loss')\n",
        "# axes[1].legend()\n",
        "\n",
        "# # Speckle Noise\n",
        "# axes[2].plot(history_speckle.history['loss'], label='Train')\n",
        "# axes[2].plot(history_speckle.history['val_loss'], label='Test')\n",
        "# axes[2].set_title(\"Speckle Noise\")\n",
        "# axes[2].set_xlabel('Epochs')\n",
        "# axes[2].legend()\n",
        "\n",
        "# # Salt & Pepper Noise\n",
        "# # axes[2].plot(history_sp.history['accuracy'], label='Train')\n",
        "# # axes[2].plot(history_sp.history['val_accuracy'], label='Test')\n",
        "# # axes[2].set_title(\"Salt & Pepper Noise\")\n",
        "# # axes[2].set_xlabel('Epochs')\n",
        "# # axes[2].legend()\n",
        "\n",
        "# axes[3].plot(history_sp.history['loss'], label='Train')\n",
        "# axes[3].plot(history_sp.history['val_loss'], label='Test')\n",
        "# axes[3].set_title(\"Salt & Pepper Noise\")\n",
        "# axes[3].set_xlabel('Epochs')\n",
        "# axes[3].legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics modèles avec custom loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Visualisation des pertes d'apprentissage (Train) et de validation (Test) des modèles avec une custom loss\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
        "\n",
        "# # Gaussian Noise\n",
        "# # axes[0].plot(history_gaussian_kl.history['loss'], label='Train')\n",
        "# # axes[0].plot(history_gaussian_kl.history['val_loss'], label='Test')\n",
        "# # axes[0].set_title(\"Gaussian Noise kl\")\n",
        "# # axes[0].set_xlabel('Epochs')\n",
        "# # axes[0].set_ylabel('Loss')\n",
        "# # axes[0].legend()\n",
        "\n",
        "# # # Poisson Noise\n",
        "# # axes[1].plot(history_poisson_kl.history['loss'], label='Train')\n",
        "# # axes[1].plot(history_poisson_kl.history['val_loss'], label='Test')\n",
        "# # axes[1].set_title(\"Poisson Noise kl\")\n",
        "# # axes[1].set_xlabel('Epochs')\n",
        "# # axes[1].set_ylabel('Loss')\n",
        "# # axes[1].legend()\n",
        "\n",
        "# # # Speckle Noise\n",
        "# # axes[2].plot(history_speckle_kl.history['loss'], label='Train')\n",
        "# # axes[2].plot(history_speckle_kl.history['val_loss'], label='Test')\n",
        "# # axes[2].set_title(\"Speckle Noise kl\")\n",
        "# # axes[2].set_xlabel('Epochs')\n",
        "# # axes[2].legend()\n",
        "\n",
        "# # Salt & Pepper Noise\n",
        "# # axes[3].plot(history_sp_kl.history['loss'], label='Train')\n",
        "# # axes[3].plot(history_sp_kl.history['val_loss'], label='Test')\n",
        "# # axes[3].set_title(\"Salt & Pepper Noise\")\n",
        "# # axes[3].set_xlabel('Epochs')\n",
        "# # axes[3].legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvXI-ynT6a3t"
      },
      "outputs": [],
      "source": [
        "print(\"Dimensions des données :\")\n",
        "print(\"x_test shape:\", x_test.shape)          # Doit être (N, 256, 256, 3)\n",
        "\n",
        "print(\"Modèle input shape:\", autoencoder_gaussian.input_shape)  # Doit être (None, 256, 256, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd0uY7-b6a3t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import uniform_filter\n",
        "\n",
        "def psnr(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1.0\n",
        "    return 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "\n",
        "def ssim_v1(original, compressed, window_size=11):\n",
        "    original = original.astype(np.float32)\n",
        "    compressed = compressed.astype(np.float32)\n",
        "\n",
        "    if original.shape != compressed.shape:\n",
        "        print(f\"Shape mismatch: {original.shape} vs {compressed.shape}\")\n",
        "        return np.nan\n",
        "\n",
        "    C1 = (0.01 * 1) ** 2  # 1.0 si image normalisée\n",
        "    C2 = (0.03 * 1) ** 2\n",
        "\n",
        "    # Moyennes locales\n",
        "    mu1 = uniform_filter(original, window_size)\n",
        "    mu2 = uniform_filter(compressed, window_size)\n",
        "\n",
        "    mu1_sq = mu1 ** 2\n",
        "    mu2_sq = mu2 ** 2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    # Variances locales\n",
        "    sigma1_sq = uniform_filter(original ** 2, window_size) - mu1_sq\n",
        "    sigma2_sq = uniform_filter(compressed ** 2, window_size) - mu2_sq\n",
        "    sigma12 = uniform_filter(original * compressed, window_size) - mu1_mu2\n",
        "\n",
        "    # SSIM map\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
        "               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    return np.mean(ssim_map)\n",
        "\n",
        "def visualize_denoising(model, clean_images, noisy_images, num_samples=3):\n",
        "    num_samples = min(num_samples, len(clean_images))\n",
        "    print(f\"\\nVisualisation de {num_samples} échantillons...\")\n",
        "\n",
        "    try:\n",
        "        denoised = model.predict(noisy_images[:num_samples], verbose=0)\n",
        "        print(\"Prédiction réussie.\")\n",
        "    except Exception as e:\n",
        "        print(\"\\nÉchec de prédiction :\")\n",
        "        print(f\"Erreur : {e}\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(15, 8), dpi=100)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # print(\"clean:\", clean_images[i].shape)\n",
        "        # print(\"noisy:\", noisy_images[i].shape)\n",
        "        # print(\"denoised:\", denoised[i].shape)\n",
        "        # Valeurs par défaut\n",
        "        psnr_n = psnr_d = float('nan')\n",
        "        ssim_value_n = ssim_value_d = float('nan')\n",
        "\n",
        "        try:\n",
        "            psnr_n = psnr(clean_images[i], noisy_images[i])\n",
        "            psnr_d = psnr(clean_images[i], denoised[i])\n",
        "            ssim_value_n = ssim_v1(clean_images[i], noisy_images[i])\n",
        "            ssim_value_d = ssim_v1(clean_images[i], denoised[i])\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du calcul des métriques pour l'image {i} : {e}\")\n",
        "\n",
        "        cmap_mode = 'gray' if clean_images[i].shape[-1] == 1 else None\n",
        "\n",
        "        # Image originale\n",
        "        plt.subplot(3, num_samples, i + 1)\n",
        "        plt.imshow(clean_images[i].squeeze(), cmap=cmap_mode)\n",
        "        plt.title(\"Original\", fontsize=8)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Image bruitée\n",
        "        plt.subplot(3, num_samples, i + 1 + num_samples)\n",
        "        plt.imshow(noisy_images[i].squeeze(), cmap=cmap_mode)\n",
        "        plt.title(f\"Noisy\\nPSNR: {psnr_n:.2f} dB\", fontsize=8)\n",
        "        plt.text(0, 15, f\"SSIM value: {ssim_value_n:.2f}\", color='white', fontsize=8, backgroundcolor='black')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Image débruitée\n",
        "        plt.subplot(3, num_samples, i + 1 + 2 * num_samples)\n",
        "        # plt.imshow(denoised[i].squeeze(), cmap=cmap_mode)\n",
        "        img = denoised[i].squeeze()\n",
        "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "        plt.imshow(img, cmap=cmap_mode)\n",
        "        plt.title(f\"Denoised\\nPSNR: {psnr_d:.2f} dB\", fontsize=8)\n",
        "        plt.text(0, 15, f\"SSIM value: {ssim_value_d:.2f}\", color='white', fontsize=8, backgroundcolor='black')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"Visualisation terminée !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jizbdqAC6a3t"
      },
      "outputs": [],
      "source": [
        "# Test final\n",
        "print(\"=== Test de visualisation ===\")\n",
        "print(\"x_test_noisy shape:\", x_test_noisy_gaussian.shape)  # Doit être (N, 256, 256, 3)\n",
        "print(\"== Gaussian ==\")\n",
        "visualize_denoising(autoencoder_gaussian, x_test[:3], x_test_noisy_gaussian[:3])  # Test avec 3 échantillons\n",
        "print(\"== Poisson ==\")\n",
        "visualize_denoising(autoencoder_poisson, x_test[:3], x_test_noisy_poisson[:3])  # Test avec 3 échantillons\n",
        "print(\"== Speckle ==\")\n",
        "visualize_denoising(autoencoder_speckle, x_test[:3], x_test_noisy_speckle[:3])  # Test avec 3 échantillons\n",
        "print(\"== Sp ==\")\n",
        "visualize_denoising(autoencoder_sp, x_test[:3], x_test_noisy_sp[:3])  # Test avec 3 échantillons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Autoencodeur en cascade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "# Pipeline : image bruitée passe dans chaque autoencodeur à la suite\n",
        "\n",
        "# Création du modèle de cascade\n",
        "# Chaque autoencodeur prend en entrée la sortie du précédent\n",
        "input_cascade = Input(shape=(256, 256, 3), name=\"input_cascade\")\n",
        "\n",
        "x1 = autoencoder_gaussian(input_cascade)\n",
        "x2 = autoencoder_poisson(x1)\n",
        "x3 = autoencoder_sp(x2)\n",
        "x4 = autoencoder_speckle(x3)\n",
        "\n",
        "cascade_model = models.Model(inputs=input_cascade, outputs=x4, name=\"denoising_cascade\")\n",
        "\n",
        "\n",
        "\n",
        "# test du modèle en cascade\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample = x_test_noisy_gaussian[0:1]  # Une image bruitée\n",
        "\n",
        "denoised = cascade_model.predict(sample)\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(sample[0])\n",
        "plt.title(\"Image bruitée\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(x_test[0])\n",
        "plt.title(\"Image propre (vérité)\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(denoised[0])\n",
        "plt.title(\"Image débruitée (cascade)\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
